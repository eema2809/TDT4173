{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/kxzcl1nj68bdr_rt5h1lbr180000gn/T/ipykernel_98210/1135257269.py:36: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
      "/var/folders/f6/kxzcl1nj68bdr_rt5h1lbr180000gn/T/ipykernel_98210/1135257269.py:37: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 594.7644197\ttotal: 15.4ms\tremaining: 15.4s\n",
      "200:\tlearn: 192.8596165\ttotal: 1.38s\tremaining: 5.47s\n",
      "400:\tlearn: 180.5368032\ttotal: 2.57s\tremaining: 3.84s\n",
      "600:\tlearn: 174.3298784\ttotal: 3.68s\tremaining: 2.44s\n",
      "800:\tlearn: 169.6346673\ttotal: 4.77s\tremaining: 1.18s\n",
      "999:\tlearn: 164.5558480\ttotal: 5.82s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/kxzcl1nj68bdr_rt5h1lbr180000gn/T/ipykernel_98210/1135257269.py:36: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
      "/var/folders/f6/kxzcl1nj68bdr_rt5h1lbr180000gn/T/ipykernel_98210/1135257269.py:37: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 92.3626894\ttotal: 8.43ms\tremaining: 8.42s\n",
      "200:\tlearn: 35.2293994\ttotal: 1.19s\tremaining: 4.73s\n",
      "400:\tlearn: 33.2446950\ttotal: 2.26s\tremaining: 3.38s\n",
      "600:\tlearn: 32.1726808\ttotal: 3.34s\tremaining: 2.21s\n",
      "800:\tlearn: 31.2183083\ttotal: 4.42s\tremaining: 1.1s\n",
      "999:\tlearn: 30.4627761\ttotal: 5.53s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/kxzcl1nj68bdr_rt5h1lbr180000gn/T/ipykernel_98210/1135257269.py:36: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
      "/var/folders/f6/kxzcl1nj68bdr_rt5h1lbr180000gn/T/ipykernel_98210/1135257269.py:37: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 61.9661959\ttotal: 8.94ms\tremaining: 8.94s\n",
      "200:\tlearn: 26.2793889\ttotal: 1.23s\tremaining: 4.88s\n",
      "400:\tlearn: 24.2466777\ttotal: 2.53s\tremaining: 3.78s\n",
      "600:\tlearn: 23.1525407\ttotal: 3.75s\tremaining: 2.49s\n",
      "800:\tlearn: 22.3760541\ttotal: 4.93s\tremaining: 1.22s\n",
      "999:\tlearn: 21.6791932\ttotal: 6.07s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "\n",
    "def preprocess_data(targets, observed, estimated, test):\n",
    "    \"\"\"\n",
    "    Preprocess the data by resampling, merging with targets, and dropping unnecessary columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - targets: Target dataframe with 'time' and target values.\n",
    "    - observed: Dataframe with observed features.\n",
    "    - estimated: Dataframe with estimated features.\n",
    "    - test: Dataframe with test features.\n",
    "    \n",
    "    Returns:\n",
    "    - Preprocessed dataframes ready for training and testing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the datetime columns are in datetime format\n",
    "    targets['time'] = pd.to_datetime(targets['time'])\n",
    "    observed['date_forecast'] = pd.to_datetime(observed['date_forecast'])\n",
    "    estimated['date_forecast'] = pd.to_datetime(estimated['date_forecast'])\n",
    "    test['date_forecast'] = pd.to_datetime(test['date_forecast'])\n",
    "\n",
    "    # Resample observed, estimated, and test data to 1 hour using mean() as aggregator\n",
    "    # and drop rows where all columns are NaN\n",
    "    observed_resampled = observed.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
    "    estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
    "    test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
    "    \n",
    "    # Merge the observed and estimated data\n",
    "    weather_data = pd.concat([observed_resampled, estimated_resampled])\n",
    "\n",
    "    # Merge with target values\n",
    "    merged_data = pd.merge(targets, weather_data, how='inner', left_on='time', right_on='date_forecast')\n",
    "\n",
    "    # Drop non-feature columns\n",
    "    merged_data = merged_data.drop(columns=['time', 'date_forecast', 'pv_measurement'])\n",
    "    \n",
    "    return merged_data, test_resampled\n",
    "\n",
    "locations = ['A', 'B', 'C']\n",
    "all_predictions = []\n",
    "\n",
    "for loc in locations:\n",
    "    # Load your data\n",
    "    train = pd.read_parquet(f'{loc}/train_targets.parquet').fillna(0)\n",
    "    X_train_estimated = pd.read_parquet(f'{loc}/X_train_estimated.parquet')\n",
    "    X_train_observed = pd.read_parquet(f'{loc}/X_train_observed.parquet')\n",
    "    X_test_estimated = pd.read_parquet(f'{loc}/X_test_estimated.parquet')\n",
    "\n",
    "   # Preprocess data\n",
    "    X_train, X_test = preprocess_data(train, X_train_observed, X_train_estimated, X_test_estimated)\n",
    "    y = train['pv_measurement'].values\n",
    "\n",
    "    # Ensure X and y have the same length\n",
    "    min_length = min(len(X_train), len(y))\n",
    "    X_train, y_train = X_train.iloc[:min_length], y[:min_length]\n",
    "    \n",
    "    #X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and Train model\n",
    "    model = CatBoostRegressor(loss_function='MAE', learning_rate=0.1, verbose=200)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using X_test_estimated data\n",
    "    # Ensure that X_test_estimated is processed similarly to how training data was processed before predictions\n",
    "    # X_test_processed = preprocess_test_data(X_test_estimated)\n",
    "    predictions = model.predict(X_test)  # Ensure preprocessing of X_test_estimated before using it.\n",
    "    \n",
    "    # Store the predictions in all_predictions list\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "# Concatenate all predictions\n",
    "final_predictions = np.concatenate(all_predictions)\n",
    "\n",
    "# Save the final_predictions to CSV\n",
    "df = pd.DataFrame(final_predictions, columns=['prediction'])\n",
    "df['id'] = df.index\n",
    "df = df[['id', 'prediction']]\n",
    "df.to_csv('final_predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
