{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/kxzcl1nj68bdr_rt5h1lbr180000gn/T/ipykernel_11245/2561023510.py:37: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
      "/var/folders/f6/kxzcl1nj68bdr_rt5h1lbr180000gn/T/ipykernel_11245/2561023510.py:38: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 599.3576502\ttotal: 7.06ms\tremaining: 7.05s\n",
      "200:\tlearn: 195.5278459\ttotal: 1.11s\tremaining: 4.41s\n",
      "400:\tlearn: 180.7882932\ttotal: 2.43s\tremaining: 3.63s\n",
      "600:\tlearn: 174.8383528\ttotal: 3.47s\tremaining: 2.3s\n",
      "800:\tlearn: 168.9150358\ttotal: 4.44s\tremaining: 1.1s\n",
      "999:\tlearn: 163.3484242\ttotal: 5.39s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/kxzcl1nj68bdr_rt5h1lbr180000gn/T/ipykernel_11245/2561023510.py:37: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
      "/var/folders/f6/kxzcl1nj68bdr_rt5h1lbr180000gn/T/ipykernel_11245/2561023510.py:38: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 92.6790690\ttotal: 7.85ms\tremaining: 7.84s\n",
      "200:\tlearn: 35.3088242\ttotal: 1.07s\tremaining: 4.26s\n",
      "400:\tlearn: 33.3564343\ttotal: 2.08s\tremaining: 3.11s\n",
      "600:\tlearn: 31.7515480\ttotal: 3.16s\tremaining: 2.1s\n",
      "800:\tlearn: 30.6651960\ttotal: 4.24s\tremaining: 1.05s\n",
      "999:\tlearn: 29.7470238\ttotal: 5.31s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/kxzcl1nj68bdr_rt5h1lbr180000gn/T/ipykernel_11245/2561023510.py:37: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
      "/var/folders/f6/kxzcl1nj68bdr_rt5h1lbr180000gn/T/ipykernel_11245/2561023510.py:38: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 62.2962634\ttotal: 6.74ms\tremaining: 6.73s\n",
      "200:\tlearn: 26.1341178\ttotal: 1.04s\tremaining: 4.15s\n",
      "400:\tlearn: 24.2091846\ttotal: 2.11s\tremaining: 3.15s\n",
      "600:\tlearn: 23.0368980\ttotal: 3.29s\tremaining: 2.18s\n",
      "800:\tlearn: 22.3315588\ttotal: 4.38s\tremaining: 1.09s\n",
      "999:\tlearn: 21.6950144\ttotal: 5.5s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "\n",
    "def preprocess_data(targets, observed, estimated, test):\n",
    "    \"\"\"\n",
    "    Preprocess the data by resampling, merging with targets, and dropping unnecessary columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - targets: Target dataframe with 'time' and target values.\n",
    "    - observed: Dataframe with observed features.\n",
    "    - estimated: Dataframe with estimated features.\n",
    "    - test: Dataframe with test features.\n",
    "    \n",
    "    Returns:\n",
    "    - Preprocessed dataframes ready for training and testing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the datetime columns are in datetime format\n",
    "    targets['time'] = pd.to_datetime(targets['time'])\n",
    "    observed['date_forecast'] = pd.to_datetime(observed['date_forecast'])\n",
    "    estimated['date_forecast'] = pd.to_datetime(estimated['date_forecast'])\n",
    "    test['date_forecast'] = pd.to_datetime(test['date_forecast'])\n",
    "\n",
    "    # Resample observed, estimated, and test data to 1 hour using mean() as aggregator\n",
    "    # and drop rows where all columns are NaN\n",
    "    observed_resampled = observed.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
    "    estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
    "    test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
    "    \n",
    "    # Merge the observed and estimated data\n",
    "    weather_data = pd.concat([observed_resampled, estimated_resampled])\n",
    "\n",
    "    # Merge with target values\n",
    "    merged_data = pd.merge(targets, weather_data, how='inner', left_on='time', right_on='date_forecast')\n",
    "\n",
    "    # Drop non-feature columns\n",
    "    merged_data = merged_data.drop(columns=['time', 'date_forecast', 'pv_measurement'])\n",
    "    \n",
    "    return merged_data, test_resampled\n",
    "\n",
    "locations = ['A', 'B', 'C']\n",
    "all_predictions = []\n",
    "\n",
    "for loc in locations:\n",
    "    # Load your data\n",
    "    train = pd.read_parquet(f'{loc}/train_targets.parquet').fillna(0)\n",
    "    X_train_estimated = pd.read_parquet(f'{loc}/X_train_estimated.parquet')\n",
    "    X_train_observed = pd.read_parquet(f'{loc}/X_train_observed.parquet')\n",
    "    X_test_estimated = pd.read_parquet(f'{loc}/X_test_estimated.parquet')\n",
    "\n",
    "   # Preprocess data\n",
    "    X_train, X_test = preprocess_data(train, X_train_observed, X_train_estimated, X_test_estimated)\n",
    "    y = train['pv_measurement'].values\n",
    "\n",
    "    # Ensure X and y have the same length\n",
    "    min_length = min(len(X_train), len(y))\n",
    "    X, y = X_train.iloc[:min_length], y[:min_length]\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and Train model\n",
    "    model = CatBoostRegressor(loss_function='MAE', learning_rate=0.1, verbose=200)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using X_test_estimated data\n",
    "    # Ensure that X_test_estimated is processed similarly to how training data was processed before predictions\n",
    "    # X_test_processed = preprocess_test_data(X_test_estimated)\n",
    "    predictions = model.predict(X_test)  # Ensure preprocessing of X_test_estimated before using it.\n",
    "    \n",
    "    # Store the predictions in all_predictions list\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "# Concatenate all predictions\n",
    "final_predictions = np.concatenate(all_predictions)\n",
    "\n",
    "# Save the final_predictions to CSV\n",
    "df = pd.DataFrame(final_predictions, columns=['prediction'])\n",
    "df['id'] = df.index\n",
    "df = df[['id', 'prediction']]\n",
    "df.to_csv('final_predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
